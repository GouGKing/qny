import { useEffect, useRef, useState } from "react";
import './RealtimeChat.css';

export default function RealtimeChat({ onExit, roleAvatars, selectedRole }) {
  const [socket, setSocket] = useState(null);
  const [chat, setChat] = useState([]);
  const [recording, setRecording] = useState(false);
  const [callDuration, setCallDuration] = useState(0);
  const [isMuted, setIsMuted] = useState(false);
  const [isSpeakerphone, setIsSpeakerphone] = useState(false);
  const mediaRecorderRef = useRef(null);
  const audioRef = useRef(null);
  const timerRef = useRef(null);
  const streamRef = useRef(null);

  useEffect(() => {
    const ws = new WebSocket("ws://localhost:3001");
    ws.onopen = () => console.log("[Realtime] ws open");
    ws.onmessage = (e) => {
      try {
        const data = JSON.parse(e.data);
        if (data.type === "partial-stt") {
          // å®æ—¶è¯†åˆ«ç»“æœ
          setChat(prev => {
            const arr = [...prev];
            if (arr.length === 0 || arr[arr.length - 1].role !== "AIæ­£åœ¨æ€è€ƒ...") {
              arr.push({ user: data.text, role: "AIæ­£åœ¨æ€è€ƒ..." });
            } else {
              arr[arr.length - 1].user = data.text;
            }
            return arr;
          });
        } else if (data.type === "user-text") {
          setChat(prev => {
            const arr = [...prev];
            if (arr.length > 0) {
              arr[arr.length - 1].user = data.text;
            }
            return arr;
          });
        } else if (data.type === "reply-text") {
          setChat(prev => {
            const arr = [...prev];
            if (arr.length > 0) {
              arr[arr.length - 1].role = data.text;
            }
            return arr;
          });
        } else if (data.type === "reply-audio") {
          const audioDataUrl = "data:audio/wav;base64," + data.audio;
          if (audioRef.current) {
            audioRef.current.pause();
            audioRef.current = null;
          }
          const audio = new Audio(audioDataUrl);
          audioRef.current = audio;
          audio.play().catch(err => console.error("éŸ³é¢‘æ’­æ”¾å¤±è´¥:", err));
        }
      } catch (err) {
        console.error("[Realtime] æ¶ˆæ¯è§£æå¤±è´¥:", err);
      }
    };
    setSocket(ws);

    return () => {
      ws.close();
      if (audioRef.current) audioRef.current.pause();
      if (timerRef.current) clearInterval(timerRef.current);
    };
  }, []);

  // æ ¼å¼åŒ–é€šè¯æ—¶é•¿
  const formatDuration = (seconds) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  async function startRecording() {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    streamRef.current = stream;
    const mr = new MediaRecorder(stream, { mimeType: "audio/webm" });
    mediaRecorderRef.current = mr;

    mr.ondataavailable = async (e) => {
      if (e.data.size > 0 && socket && socket.readyState === WebSocket.OPEN) {
        const ab = await e.data.arrayBuffer();
        const b64 = btoa(String.fromCharCode(...new Uint8Array(ab)));
        socket.send(JSON.stringify({ type: "audio-chunk", chunk: b64, isAgentMode: true }));
      }
    };

    mr.start(250);
    setRecording(true);
    setCallDuration(0);
    
    // å¼€å§‹è®¡æ—¶
    timerRef.current = setInterval(() => {
      setCallDuration(prev => prev + 1);
    }, 1000);
  }

  function stopRecording() {
    if (mediaRecorderRef.current) mediaRecorderRef.current.stop();
    if (socket && socket.readyState === WebSocket.OPEN) {
      socket.send(JSON.stringify({ type: "stop", isAgentMode: true }));
    }
    setRecording(false);
    
    // åœæ­¢è®¡æ—¶
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }
    
    // åœæ­¢éŸ³é¢‘æµ
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
  }

  // é™éŸ³åŠŸèƒ½
  const toggleMute = () => {
    if (streamRef.current) {
      const audioTrack = streamRef.current.getAudioTracks()[0];
      audioTrack.enabled = !audioTrack.enabled;
      setIsMuted(!audioTrack.enabled);
    }
  };

  // å…æåŠŸèƒ½ï¼ˆæ¨¡æ‹Ÿï¼‰
  const toggleSpeakerphone = () => {
    setIsSpeakerphone(prev => !prev);
    // å®é™…çš„å…æåŠŸèƒ½éœ€è¦Web Audio APIçš„æ›´å¤šè®¾ç½®
  };

  // è·å–å½“å‰è§’è‰²å¤´åƒ
  const currentAvatar = roleAvatars && selectedRole ? roleAvatars[selectedRole.name] : "ğŸ¤–";
  // è·å–å½“å‰è§’è‰²åç§°
  const currentRoleName = selectedRole ? selectedRole.name : "AIè¯­éŸ³åŠ©æ‰‹";

  return (
    <div className="realtime-chat-page">
      <div className="realtime-chat-header">
        <button className="realtime-back-button" onClick={onExit} style={{ opacity: recording ? 0.6 : 1, cursor: recording ? 'not-allowed' : 'pointer' }} disabled={recording}>
          <svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M18.5 30.5L8.5 20L18.5 9.5" stroke="#2F88FF" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"/>
            <path d="M26.5 30.5L16.5 20L26.5 9.5" stroke="#43CCF8" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"/>
          </svg>
        </button>
        <h2>{currentRoleName}å®æ—¶é€šè¯</h2>
        <div className="realtime-duration-display">
          {recording && formatDuration(callDuration)}
        </div>
      </div>

      <div className="realtime-call-container">
        {/* è§’è‰²å¤´åƒ */}
        <div className={`realtime-avatar-container ${isMuted ? 'muted' : ''}`}>
          {currentAvatar}
        </div>
        
        {/* é€šè¯çŠ¶æ€æ˜¾ç¤º */}
        {recording ? (
          <div className="realtime-status-text">
            é€šè¯ä¸­...
          </div>
        ) : (
          <div className="realtime-status-text">
            å‡†å¤‡é€šè¯
          </div>
        )}
        
        {/* é€šè¯ä¿¡æ¯ */}
        <div className="realtime-call-info">
          <div className="realtime-role-name">{currentRoleName}</div>
          <div className="realtime-call-hint">ç‚¹å‡»å¼€å§‹æŒ‰é’®å¼€å§‹é€šè¯</div>
        </div>
        
        {/* é€šè¯è®°å½• */}
        {chat.length > 0 && (
          <div className="realtime-chat-history">
            {chat.map((c, i) => (
              <div key={i} className="realtime-chat-message">
                <div className="realtime-user-text">
                  ä½ : {c.user}
                </div>
                <div className="realtime-ai-text">
                  {currentAvatar}: {c.role}
                </div>
              </div>
            ))}
          </div>
        )}
      </div>

      {/* é€šè¯æ§åˆ¶æŒ‰é’® */}
      {recording ? (
        <div className="realtime-call-controls">
          {/* è¾…åŠ©åŠŸèƒ½æŒ‰é’® */}
          <div className="realtime-auxiliary-buttons">
            <button
              onClick={toggleMute}
              className={isMuted ? 'muted' : ''}
            >
              {isMuted ? 'ğŸ”‡' : 'ğŸ”Š'}
            </button>
            <button
              onClick={toggleSpeakerphone}
              className={isSpeakerphone ? 'speakerphone' : ''}
            >
              {isSpeakerphone ? 'ğŸ”Š' : 'ğŸ“±'}
            </button>
          </div>
          
          {/* æŒ‚æ–­æŒ‰é’® */}
          <button
            onClick={stopRecording}
            className="realtime-hangup-button"
          >
            ğŸ“
          </button>
        </div>
      ) : (
        <div className="realtime-combined-buttons">
          <button className="realtime-record-button" onClick={startRecording}>
            ğŸ¤ å¼€å§‹é€šè¯
          </button>
        </div>
      )}
    </div>
  );
}