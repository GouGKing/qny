初步想法为不使用成熟LLM模型，使用免费本地LLM模型跑通，后续使用成熟LLM模型进行替换
前端：react + vite
后端：node.js
本地LLM模型：ollama 拉取运行 mistral
声音处理：whisper piper python
实时对话：websocket
